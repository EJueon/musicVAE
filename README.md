# MusicVAE (Pytorch)
Music VAE : https://arxiv.org/pdf/1803.05428.pdf
Groove MIDI Dataset: https://magenta.tensorflow.org/datasets/groove

#### ë…¼ë¬¸ ìš”ì•½
<p align="center">
<img width="519" alt="image" src="https://github.com/EJueon/music_VAE/assets/93572176/44233bdf-8717-4471-bad1-3cbab582d77c">
</p>

- RNN ê³„ì—´ì˜ ì‹ ê²½ë§ì˜ ê·¼ë³¸ì ì¸ í•œê³„ì¸ long-term structureì— ëŒ€í•´ì„œ ë¹„êµì  ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ëŠ” ë¬¸ì œ(posterior collapse)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ì œì•ˆ
- ê¸°ë³¸ì ì¸ RNN ê¸°ë°˜ Encoder-Decoder(Seq2Seq)ì´ ì•„ë‹ˆë¼ Variational Autoencoder(VAE)ë¥¼ ì‚¬ìš©í•˜ì˜€ìŒ, ELBO loss ì‚¬ìš©
- ì¸ì½”ë”ì—ì„œ ìƒì„±í•˜ëŠ” latent representationì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶€ë¶„ ì‹œí€€ìŠ¤ì— ëŒ€í•œ embedding ìƒì„±. ë””ì½”ë”ì— í•´ë‹¹ embeddingê³¼ ì…ë ¥ê°’ì„ ì…ë ¥í•˜ëŠ” ê²ƒìœ¼ë¡œ ì „ì²´ latent representationì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ posterior collapse ë¬¸ì œë¥¼ ë‹¤ì†Œ íšŒí”¼í•  ìˆ˜ ìˆìŒ
- ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ê²©ì¸ flatë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŒ 
<br /> <br /> <br /> 





## How to use
#### preprocess
```shell
python main.py --opt=preprocess --config=../config path
```

#### train
```shell
python main.py --opt=train --config=../config path
```
#### generate
```shell
python main.py --opt=generate --config=../config path --model_path=../data/ckpt/epoch_100.pt --file_path=../dataset/test.midi
```

<br /> <br /> <br /> 

## ê³¼ì œ ê°œìš”
- **ì£¼ì œ** : Music VAE, Groove MIDI Datasetë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬-í•™ìŠµ ê³¼ì •ì„ ê±°ì³ 4ë§ˆë””ì— í•´ë‹¹í•˜ëŠ” ë“œëŸ¼ ìƒ˜í”Œ ì¶”ì¶œ
- **ê¸°ê°„** : 23.5.31 10:00 ~ 23.06.01 10:00

- **í”„ë¡œì íŠ¸ êµ¬ì¡°**
        
    ```bash
        â”œâ”€ configs
        â”‚  â””â”€ basic_config.yaml
        â”œâ”€ src
        â”‚  â”œâ”€ main.py
        â”‚  â”œâ”€ models
        â”‚  â”‚  â”œâ”€ dataloader.py
        â”‚  â”‚  â”œâ”€ metrics.py
        â”‚  â”‚  â””â”€ musicVAE.py
        â”‚  â””â”€ utils
        â”‚     â”œâ”€ __init__.py
        â”‚     â”œâ”€ process_utils.py
        â”‚     â””â”€ trainer.py
        â”œâ”€ data
        â”œâ”€ requirements.txt
        â””â”€ .gitignore 
    ```
        
- **ë°ì´í„°ì…‹ êµ¬ì¡°**
        
    ```jsx
        filepath : ì „ì²˜ë¦¬ì‹œ MIDI ë°ì´í„°ì˜ íŒŒì¼ëª… ë° ê²½ë¡œ
        data : drum beatsë§Œì„ ì¶”ì¶œí•˜ì—¬ ì‹œí€€ìŠ¤í™”ëœ MIDI ë°ì´í„° (2**drum_classes)
    ```
<br /> <br /> <br /> 
## ê³¼ì œ ì§„í–‰ì‚¬í•­ 

> ## ğŸ“Œ 
> - Preprocessing : 4/4 ê¸°ì¤€ ë“œëŸ¼ pitches ì „ì²˜ë¦¬
> - Training : MusicVAE ëª¨ë¸ ë° í•™ìŠµ í‰ê°€ ëª¨ë“ˆ êµ¬í˜„
> - Generate : (TODO) 4 ë§ˆë”” ê¸°ì¤€ MIDI ìƒì„±
    
### Preprocessing

- pretty_midi ëª¨ë“ˆì„ í†µí•´ MIDI íŒŒì¼ë¡œ ë¶€í„° ë°ì´í„° ì¶”ì¶œ
- pitchesë¥¼ 9ê°œì˜ ëŒ€í‘œ í´ë˜ìŠ¤ë¡œ ë§¤í•‘í•˜ì—¬ ì–‘ìí™” 
- ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ 2^9(512)ê°œì˜ ìœ í˜•ìœ¼ë¡œ ë³€í™˜ 
- ì–‘ìí™”ëœ MIDI ë°ì´í„° ì €ì¥ 


### Model Structure
#### Bidirectional encoder 
- 2-layer Bidirectional LSTM encoder
- hidden stateë¥¼ í† ëŒ€ë¡œ muì™€ sigma ì¸ì½”ë”©, ê°ê°ì„ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´ì„œ linear layer ì‚¬ìš© (Eq.6, Eq.7)
- z = mu + (sigma * epsilon) (Eq.2)ë¡œ latent representation z ì¸ì½”ë”©. 
- zëŠ” embedding vectorë¥¼ ì—°ì‚°í•˜ê¸° ìš©ì´í•˜ë„ë¡ ì°¨ì› ë³€ê²½ (batch_size, latent_dim)  -> (batch_size, self.U, self.input_size)       

#### Hierarchical decoder 
- u âˆˆ U, UëŠ” ë¶€ë¶„ ì‹œí€€ìŠ¤ì˜ ê°œìˆ˜ì¼ ë•Œ, ê° z[:, u, :]ì— ëŒ€í•´ì„œ embedding ê°’ìœ¼ë¡œ ë³€í™˜
- embeddingê³¼ ì´ì— í•´ë‹¹í•˜ëŠ” ì…ë ¥ ë°ì´í„°ì˜ ë¶€ë¶„ ì‹œí€€ìŠ¤ë¥¼ í•¨ê»˜ ë””ì½”ë”ì— ì…ë ¥


#### Training 
- sequence length = 64 (4 bar)
- learning rate = 1e-3
- AdamW optimizer 
- CosineAnnealingWarmRestarts scheduler
- criterion = ELBO loss
- train datasetê³¼ dev datasetì€ 8:2ë¡œ ê³ ì •í•˜ì—¬ í•™ìŠµ ì§„í–‰ 

<img width="967" alt="" src="https://github.com/EJueon/musicVAE/assets/93572176/41131e3f-36d1-4f6a-a676-87ada2acc8d3">
